---
title: 打造為身障者量身設計的 APP｜第十一屆梅竹黑客松全紀錄
date: "2024-04-20"
author: James
tags: Life, Hackathon
image: /images/life/11th-meichu-hackathon/meichu-hackathon.jpg
description: "梅竹黑客松是一個比賽時長沒有很長的黑客松比賽，先簡單介紹一下他的賽制，總共分成「黑客組」跟「創客組」，黑客組會邀請各大企業參與命題，除了要提出專案企劃以外，同時還要在幾天的時間內做出最小可行性產品，所以是一項兼具企劃發想跟技術實力的比賽，但是為了不要讓梅竹黑客松的參與人員侷限在技術人才，主辦方還設立了「創客組」，由新竹市政府命題，參賽者就不需要真的實作出產品，只要提出完善的專案計畫即可。"
readTime: 3
---

梅竹黑客松是一個比賽時長沒有很長的黑客松比賽，先簡單介紹一下他的賽制，總共分成「黑客組」跟「創客組」，黑客組會邀請各大企業參與命題，除了要提出專案企劃以外，同時還要在幾天的時間內做出最小可行性產品，所以是一項兼具企劃發想跟技術實力的比賽，但是為了不要讓梅竹黑客松的參與人員侷限在技術人才，主辦方還設立了「創客組」，由新竹市政府命題，參賽者就不需要真的實作出產品，只要提出完善的專案計畫即可。

對於我來說，當然就優先選擇黑客組了，黑客組分成 6, 7 組，每一組都會由一個企業命題，這次參與命題的企業有 Google, LINE, NXP 等等，每一組會競爭出前三名，而各組的第一名還可以在最後的決賽角逐「梅竹大獎」。

因為前兩年擔任梅竹黑客松籌備幹部的關係，所以很自然的就跟大家講好說一定要再回來參加比賽，除了累積實務經驗，也順便看看下一屆的學弟妹籌備的如何。

### **抽中夢幻命題 Google，卻卡在題目想不出來**

報名的時候可以填寫志願表，截止報名以後就會進行抽籤分組，我們很幸運抽到最想要去的企業 - Google，而各企業會安排工作坊，算是一種企業參訪，也順便會跟大家解釋今年的題目細節，那在工作坊之後比賽就算是正式開始了。

今年的題目是「利用 Accessibility API 在 Pixel 手機上打造一個 APP 來提升身障人士的生活品質」，身障人士不限視障、聽障等等，想得到的其實都可以做，但沒想到整個比賽環節最難的就是這個部分，身障人士離我們的生活太遙遠，我們光想題材就花費超過一半的時間。

### **題目發想：比創意、拼技術還得避開競品**

黑客松題目發想需要考量幾個面向，第一個是產品可行性，我們可以很天馬行空想出一些奇葩點子，但是我們也要有能力在幾天的時間把它寫出來才行，第二個是創意，產品做得出來沒有用，畢竟其實大家都做得出來，所以題目的發想需要有一個亮點讓評審眼睛為之一亮，最後一個應該也是最難的部分了，我們必須確保市面上沒有太像的競品，如果我們花費所有時間實作出一個很厲害的專案，但是市面上明明就已經有了，評審一句話「xxx不是就已經做了這個功能了嗎」今年的獎項就跟我們無緣了。

針對這個題目我們其實也有想過很多方向，像是「協助聽障人士辨識身邊聲音的視覺系統」，讓他可以「看」見聲音，但這個專案我們可能要用什麼傅立葉轉換分析出不同聲音的波形並分離出來，這個大大超出我們的能力範圍了，我們還有想到什麼「盲人室內導航」、「手語辨識系統」等等，不過都因為市面上有競品被我們丟棄，最後我們在剩下大概五天的時間決定出了下面這個專案 - Access Pro。

### **從不會寫 App 到 Demo 上線，五天內打造最小可行性產品**

先簡單介紹一下這個專案到底在幹嘛，他有兩個部分，第一個是「Object Mode」，使用者可以直接對著 APP 說他想要找的物品，例如說一瓶麥香奶茶，我們就可以利用鏡頭定位出那個物體現在在哪裡，然後跟使用者提示要往哪個方向移動來找到物體，第二個是「Text Mode」，使用者可以拍攝一些字很小的東西，例如說食品標籤，我們就可以整理標籤上的資訊產出一個易讀的版本放大文字，並提供一問一答的聊天室可以讓使用者直接詢問標籤上他不懂的內容。所以這個專案最主要的目的是要讓視障人士提高獨立生活的能力。

技術方面下面等等會介紹，不過我們遇到最大的問題應該就是完全沒有人摸過 Android App，但離 demo 只剩下五天了，所以那五天真的是地獄，我們要先熟悉那個看起來很複雜的 Android Studio，想辦法實作出我們所有功能然後解決所有 bug。不過我記得有一個 bug 我們解到當天還沒有解出來，最後就放棄了，但現場也沒有被發現就是了滿好笑的。

### **好作品要「會賣」：設計、命名、簡報缺一不可**

除了把專案做出來，我們一致認為「包裝」也是比賽中很重要的一環，表面功夫還是得做一下。整理這篇文章的時候已經是比賽後兩三年了，回頭來看這個專案感覺很像小朋友在寫的玩具，所以我想評審應該也都是這樣認為的，那如果目標是要從一群「小朋友」中脫穎而出，還是得要做出一點亮點讓評審可以記住我們的專案，那技術跟企劃層面如果就是那樣，至少名字要想的很厲害，技術要包裝得看起來很完整，Slides 跟產品本身也要設計的好看一點讓評審會想要多停留幾秒，沒有人能夠猜到評審的喜好，但能表現的地方都盡量完善至少我相信是能夠提升回頭率的。

### **作品簡介**

簡單介紹一下五天的時間我們寫出了些什麼東西。

#### **Access Pro - Text Mode**

![image](/images/life/11th-meichu-hackathon/text-mode-introduction.png)

這個功能主要是為了視力不好的人設計的，家裡有些長輩看一些小字的時候常常會看不清楚，例如說標籤、說明書等等，因此我們設計了「文字放大鏡」來解決這個問題。
使用者可以將當下他要閱讀的文本拍攝下來，利用圖像轉文字的 API 我們可以分離出文字，再來結合大型語言模型重新整合資訊並排版再呈現給使用者，同時使用者可以根據文本的內容作提問，例如說他可以問：這瓶飲料保存期限為何？我們的 App 整合完資訊後就會回答使用者，方便他們擷取自己需要的資訊。

#### **Access Pro - Object Mode**

![image](/images/life/11th-meichu-hackathon/object-mode-introduction.png)

這個功能主要是為了讓視障者有獨立生活的能力，我們的目標是視障者在找尋物品的時候，透過影像辨識，可以根據 APP 給的提示就走到物品真正的位置。使用者首先會告訴 APP 說他想要找尋甚麼樣的物品，再來根據影像辨識的結果，APP 會提示使用者方位，例如：向左走、向右走等等，最終就可以找到目標物品。在 Demo 的時候我們就在桌上擺了好幾瓶飲料，然後讓矇眼的人只利用 APP 的提示音就找到哪一瓶是真正的麥香，算是我們設計的一個小噱頭。

### **技術架構**

![image](/images/life/11th-meichu-hackathon/text-mode-technique.png)

Text Mode 的部分我們利用 ML Kit 將圖片轉成文字，再來利用大型語言模型，給定設計過的 Prompt 讓其整合我們傳過去的資料，並讓他可以回答使用者的問題。

![image](/images/life/11th-meichu-hackathon/object-mode-technique.png)

Object Mode 我們利用 lightweight Yolov5 來處理影像判斷物體位置，我們可以直接讓輕量的模型跑在手機上，這樣可以實現離線處理的功能以及提高它的效能。再來我們使用客製化的 Dataset 來 fine tune 我們的 model，讓他可以更精準的判斷目標物體的位置。

### **總結**

最後我們是拿 Google 組第一名，決賽的第三名，對當時的我們來說也算是不錯的鼓勵了，有時候真的很難判斷評審喜歡些什麼東西，像是 Text Mode 的部分，不就是接接語言模型 api 把內容都丟過去讓使用者可以針對內容問他問題而已是吧？不過 Google 評審好像特別喜歡這個部分抓著這邊問了好多，不過決賽的評審從他們問的問題又感覺他們好像比較喜歡 Object Mode 的部分，真的是滿各有所好的，所以參賽者就是抓緊時間在 demo 前把最好的部分展現出來就可以了。

不過可能是因為自己辦過的關係所以非常清楚會場中幾乎所有細節，看到下一屆的幹部在現場壓力很大其實也是滿心疼的，有些參賽者可能會因為籌備團隊的一些細節沒有處理好或是沒有規劃周全就會對籌備方惡言相向，我自己是覺得大家可以好好給建議，這樣可以將這些建議傳承下去讓這個活動越來越好，身為籌辦方一定不會想要隨隨便便處理這個活動，大家一定是盡全力在做事，那不管做任何事情都一定會有考慮不周全的情況，既然如此一些激烈的言論我是覺得就沒有必要了，籌辦了一年大家都非常辛苦，多一點包容多幫忙給一點建議，我覺得就很足夠了。

